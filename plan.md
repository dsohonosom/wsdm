## WSDM Cup 2025 ゴールドメダル獲得に向けた取り組み計画

**目標**: WSDM Cup 2025でゴールドメダルを獲得する。

**現状**: 2024年12月16日

**提出期限**: 2025年2月3日

**使用リソース**: Google Colab Pro+ (GPU: A100 40GB)

**ベース戦略**: 過去の類似コンペ(LMSYS)の3位解法を参考に、多言語対応と時間的制約を考慮して、効率的にモデル開発を行う。

**主要戦略**:

1. **効率的なデータ活用**:
    *   コンペデータ + 厳選した追加データ
    *   効果的な疑似ラベリング (データ量/ラウンド数 調整)
    *   データ拡張 (応答順序入れ替え等)
2. **モデル選択と学習**:
    *   多言語対応の事前学習済みReward Model (例: Gemma 2-9B)
    *   パラメータ調整 (QLoRA: r=64, alpha=16, Softcapping無効化)
    *   多言語対応トークナイザー
3. **高速な推論**:
    *   8bit推論
    *   vLLM (長さベースのバッチ処理)
4. **アンサンブル**:
    *   2モデルのアンサンブル

**多言語対応**:

*   多言語Reward Modelの活用
*   (オプション) 言語別モデル
*   (オプション) 言語特徴量の活用
*   (最終手段) 機械翻訳

**タイムライン**:

| 期間        | 優先度 | タスク                                                                                                 |
| :---------- | :----- | :----------------------------------------------------------------------------------------------------- |
| 12月末まで   | 高     | データ分析、追加データ調査、多言語Reward Model調査、環境構築、ベースラインモデル学習                     |
| 1月初旬      | 高     | パラメータ調整、初期実験 (データ拡張、言語別モデル)、疑似ラベリング準備                               |
| 1月中旬      | 高     | 疑似ラベリング用データ生成、疑似ラベリング実行、本学習、異なるモデルでの学習                         |
| 1月下旬      | 高     | アンサンブル、推論高速化、最終モデル調整、ドキュメント作成、コード整理、最終提出                       |
| 通期        | -      | Kaggleフォーラム参加、公開Notebook参照、実験管理、進捗確認、タスク見直し                                |

**タスク詳細**:

**【12月末まで (～約2週間)】: データ理解、環境構築、ベースライン構築**

| タスク                                    | 詳細                                                                                                                                                                                                                                 | 期限      | 成果物                                                                                |
| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------- | :------------------------------------------------------------------------------------ |
| 1. データセットの分析 (必須)                | - データの統計情報 (言語分布、プロンプト/レスポンスの長さなど) を確認<br> - データの質を評価 (ノイズ、外れ値など) <br> - 特に多言語データに着目し、各言語のデータ量、特徴などを把握                                         | 12/20     | データ分析レポート (EDA Notebook)                                                    |
| 2. 追加データの調査と選別 (必須)              | - LMSYSコンペで提供された追加データが多言語対応しているか確認<br> - 多言語対応していない場合、類似の多言語データを収集 (例: 多言語版のUltrafeedback) <br> - 収集したデータの質を評価し、コンペデータとの整合性を確認                                   | 12/23     | 使用する追加データのリスト、データセット                                                |
| 3. 多言語対応Reward Modelの調査と選定 (必須) | - 多言語対応の事前学習済みReward Modelを調査 (例: Hugging Face Model Hub) <br> - 候補モデルの性能、ライセンス、A100 GPUでの動作可能性などを比較<br> - 最も有望なモデルを選定 (例: 多言語版のGemma 2, Llama 3)                               | 12/25     | 選定したReward Model、選定理由                                                       |
| 4. 開発環境構築 (必須)                     | - Google Colab Pro+でA100 GPUが利用できることを確認<br> - 必要なライブラリ (Transformers, vLLMなど) をインストール<br> - コードのバージョン管理 (例: Git) <br> - 実験管理ツール (例: Weights & Biases) の設定 (オプション) | 12/27     | 動作確認済みの開発環境、コードリポジトリ                                               |
| 5. ベースラインモデルの学習 (必須)            | - 選定したReward Modelをコンペデータでファインチューニング<br> - ベースラインとしての性能を評価 (精度、Log Loss) <br> - パラメータ調整の準備 (学習率、バッチサイズ、エポック数など)                                                   | 12/31     | ベースラインモデル、評価結果、初期パラメータ設定                                        |

**【1月初旬 (～約1週間)】: パラメータ調整、初期実験**

| タスク                                | 詳細                                                                                                                                                 | 期限      | 成果物                                                     |
| :------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------- | :-------- | :--------------------------------------------------------- |
| 6. パラメータ調整 (必須)               | - QLoRAの設定 (r, alpha) を調整し、最適な値を見つける<br> - 学習率、バッチサイズ、エポック数などを調整し、性能向上を図る <br> - Softcappingの無効化 (configをNoneに設定) を試す (Gemma 2の場合) | 1/4       | 最適なパラメータ設定、調整後のモデル、評価結果             |
| 7. データ拡張の検討 (オプション)        | - response_aとresponse_bを入れ替えたデータを作成し、学習データに追加 <br> - 効果があるか検証                                                       | 1/5       | データ拡張を適用したデータセット、評価結果 (効果検証)     |
| 8. 言語別モデルの検討 (オプション)        | - 主要な言語ごとにモデルを学習し、アンサンブルを試す<br> - 計算リソースと時間的制約を考慮して、実施するか判断                                         | 1/6       | 言語別モデル (実施した場合)、評価結果、実施判断の記録 |
| 9. 疑似ラベリング用データ生成の準備 (必須) | - vLLMを使用して、追加データから疑似ラベリング用データを生成する準備 <br> - 長さベースのバッチ処理を実装                                         | 1/7       | 疑似ラベリング用データ生成スクリプト                     |

**【1月中旬 (～約2週間)】: 疑似ラベリング、本学習**

| タスク                         | 詳細                                                                                                                                                                | 期限      | 成果物                                                     |
| :----------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-------- | :--------------------------------------------------------- |
| 10. 疑似ラベリング用データ生成 (必須) | - 準備したスクリプトを使用して、追加データから疑似ラベリング用データを生成 <br> - 生成データ量を調整 (時間的制約を考慮)                                                 | 1/10      | 疑似ラベリング用データセット                               |
| 11. 疑似ラベリング実行 (必須)      | - ベースラインモデル (または調整後のモデル) を使用して、生成したデータに疑似ラベルを付与 <br> - 信頼度の高い疑似ラベルを選択 (例: 複数のモデルで予測が一致したもの)           | 1/14      | 疑似ラベル付きデータセット                                 |
| 12. 本学習 (必須)              | - コンペデータと疑似ラベル付きデータを組み合わせて、最終モデルを学習 <br> - パラメータは調整済みのものを使用                                                           | 1/18      | 最終モデル (疑似ラベリング適用)                           |
| 13. 異なるモデルでの学習 (必須)      | - 選定したもう一つのモデルでも本学習を行い、アンサンブルの準備をする。                                                   | 1/21      | 最終モデル(別モデルで学習したもの)                           |

**【1月下旬 (～約1.5週間)】: アンサンブル、推論高速化、最終調整**

| タスク                                  | 詳細                                                                                                                                                                                                    | 期限      | 成果物                                                         |
| :-------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------- | :------------------------------------------------------------- |
| 14. アンサンブル (必須)                   | - 異なるモデルの予測結果を組み合わせ、性能を向上させる (例: 平均、加重平均) <br> - アンサンブルの効果を検証                                                                                              | 1/24      | アンサンブルモデル、評価結果                                   |
| 15. 推論の高速化 (必須)                 | - 8bit推論を実装し、推論時間を短縮 <br> - vLLMのバッチ処理を最適化                                                                                                                                    | 1/27      | 高速化された推論コード、推論時間計測結果                     |
| 16. 最終モデルの調整 (必須)               | - 開発データセットを用いて、最終的な性能評価を行う <br> - 必要に応じて、ハイパーパラメータの微調整や、アンサンブルの重み調整を行う                                                                   | 1/29      | 最終調整済みモデル、最終評価結果                             |
| 17. ドキュメント作成、コード整理 (必須)      | - 最終提出に必要なドキュメント (モデルの説明、学習方法、使用データなど) を作成 <br> - 提出用のコードを整理し、再現性を確保                                                                             | 1/31      | 提出用ドキュメント、整理されたコード                         |
| 18. 最終提出 (必須)                     | - 最終モデルの予測結果を提出                                                                                                                                                                              | 2/3       | 提出ファイル (submission.csv)                                |

**【通期】**

| タスク                     | 詳細                                                                                                                       | 頻度    | 成果物                            |
| :------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------ | :-------------------------------- |
| Kaggleフォーラム参加        | 情報収集、議論、他の参加者との交流                                                                                     | 毎日    | -                                 |
| 公開Notebookの参照        | 類似コンペの上位解法の実装を参考に、コードを効率化                                                                     | 適宜    | -                                 |
| 実験管理                   | 実験結果 (パラメータ、評価指標、使用データなど) を詳細に記録し、効果的な手法を特定、Weights & Biases等のツール活用 | 毎回    | 実験ログ、分析結果                  |
| 進捗確認、タスク見直し     | スケジュール通りに進んでいるか確認し、必要に応じてタスクの優先順位や期限を調整                                            | 週次    | 更新されたタイムライン、タスクリスト |

**リスク管理**:

*   **時間**: 各タスクの期限厳守。遅延発生時は、後続タスクへの影響を最小限に抑えるよう調整。優先度の低いタスクは後回し or 切り捨ても検討。
*   **多言語対応**: 性能が出ない場合は、主要言語への注力、機械翻訳の利用、データ拡張強化などを検討。
*   **GPUリソース**: A100 40GBの制限内で、モデルサイズ、バッチサイズ、学習時間を調整。